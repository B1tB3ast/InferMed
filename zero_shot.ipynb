{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Notebook for Zero-Shot Inference with CheXzero\n",
    "This notebook walks through how to use CheXzero to perform zero-shot inference on a chest x-ray image dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from eval import evaluate, bootstrap\n",
    "from zero_shot import make, make_true_labels, run_softmax_eval\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../checkpoints10gb50e/pt-imp/checkpoint_18000.pt']\n"
     ]
    }
   ],
   "source": [
    "## Define Zero Shot Labels and Templates\n",
    "\n",
    "# ----- DIRECTORIES ------ #\n",
    "cxr_filepath: str = '../test_data/cxr.h5' # filepath of chest x-ray images (.h5)\n",
    "cxr_true_labels_path: Optional[str] = '../data/groundtruth.csv' # (optional for evaluation) if labels are provided, provide path\n",
    "model_dir: str = '../checkpoints_train/pt-imp' # where pretrained models are saved (.pt) \n",
    "predictions_dir: Path = Path('../predictions-val') # where to save predictions\n",
    "cache_dir: str = predictions_dir / \"cached_val\" # where to cache ensembled predictions\n",
    "\n",
    "context_length: int = 77\n",
    "\n",
    "# ------- LABELS ------  #\n",
    "# Define labels to query each image | will return a prediction for each label\n",
    "cxr_labels: List[str] = ['Atelectasis','Cardiomegaly', \n",
    "                                      'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion',\n",
    "                                      'Lung Opacity', 'No Finding','Pleural Effusion', 'Pleural Other', 'Pneumonia', \n",
    "                                      'Pneumothorax', 'Support Devices']\n",
    "\n",
    "# ---- TEMPLATES ----- # \n",
    "# Define set of templates | see Figure 1 for more details                        \n",
    "cxr_pair_template: Tuple[str] = (\"{}\", \"no {}\")\n",
    "\n",
    "# ----- MODEL PATHS ------ #\n",
    "# If using ensemble, collect all model paths\n",
    "model_paths = ['../checkpoints_train/pt-imp/checkpoint_18000.pt']\n",
    "# for subdir, dirs, files in os.walk(model_dir):\n",
    "#     for file in files:\n",
    "#         full_dir = os.path.join(subdir, file)\n",
    "#         model_paths.append(full_dir)\n",
    "        \n",
    "print(model_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the model on the data set using ensembled models\n",
    "def ensemble_models(\n",
    "    model_paths: List[str], \n",
    "    cxr_filepath: str, \n",
    "    cxr_labels: List[str], \n",
    "    cxr_pair_template: Tuple[str], \n",
    "    cache_dir: str = None, \n",
    "    save_name: str = None,\n",
    ") -> Tuple[List[np.ndarray], np.ndarray]: \n",
    "    \"\"\"\n",
    "    Given a list of `model_paths`, ensemble model and return\n",
    "    predictions. Caches predictions at `cache_dir` if location provided.\n",
    "\n",
    "    Returns a list of each model's predictions and the averaged\n",
    "    set of predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = []\n",
    "    model_paths = sorted(model_paths) # ensure consistency of \n",
    "    print(model_paths)\n",
    "    for path in model_paths: # for each model\n",
    "        model_name = Path(path).stem\n",
    "\n",
    "        # load in model and `torch.DataLoader`\n",
    "        model, loader = make(\n",
    "            model_path=path, \n",
    "            cxr_filepath=cxr_filepath, \n",
    "        ) \n",
    "        \n",
    "        # path to the cached prediction\n",
    "        if cache_dir is not None:\n",
    "            if save_name is not None: \n",
    "                cache_path = Path(cache_dir) / f\"{save_name}_{model_name}.npy\"\n",
    "            else: \n",
    "                cache_path = Path(cache_dir) / f\"{model_name}.npy\"\n",
    "\n",
    "        # if prediction already cached, don't recompute prediction\n",
    "        if cache_dir is not None and os.path.exists(cache_path): \n",
    "            print(\"Loading cached prediction for {}\".format(model_name))\n",
    "            y_pred = np.load(cache_path)\n",
    "        else: # cached prediction not found, compute preds\n",
    "            print(\"Inferring model {}\".format(path))\n",
    "            y_pred = run_softmax_eval(model, loader, cxr_labels, cxr_pair_template)\n",
    "            if cache_dir is not None: \n",
    "                Path(cache_dir).mkdir(exist_ok=True, parents=True)\n",
    "                np.save(file=cache_path, arr=y_pred)\n",
    "        predictions.append(y_pred)\n",
    "    \n",
    "    # compute average predictions\n",
    "    print(predictions)\n",
    "    y_pred_avg = np.mean(predictions, axis=0)\n",
    "    print(y_pred_avg)\n",
    "    return predictions, y_pred_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../checkpoints10gb50e/pt-imp/checkpoint_18000.pt']\n",
      "Loading cached prediction for checkpoint_18000\n",
      "[array([[0.49611872, 0.49636057, 0.5076487 , ..., 0.51039606, 0.4975381 ,\n",
      "        0.51275533],\n",
      "       [0.5018535 , 0.50363845, 0.4970435 , ..., 0.4977175 , 0.49737707,\n",
      "        0.49912113],\n",
      "       [0.5029214 , 0.49823767, 0.5070606 , ..., 0.507116  , 0.50782096,\n",
      "        0.5144976 ],\n",
      "       ...,\n",
      "       [0.49379626, 0.49402764, 0.4913916 , ..., 0.4954754 , 0.49808016,\n",
      "        0.48922092],\n",
      "       [0.5146677 , 0.5107169 , 0.5075194 , ..., 0.5018823 , 0.51208967,\n",
      "        0.49710515],\n",
      "       [0.4972319 , 0.5026027 , 0.49866775, ..., 0.4938344 , 0.5048814 ,\n",
      "        0.49989307]], dtype=float32)]\n",
      "[[0.49611872 0.49636057 0.5076487  ... 0.51039606 0.4975381  0.51275533]\n",
      " [0.5018535  0.50363845 0.4970435  ... 0.4977175  0.49737707 0.49912113]\n",
      " [0.5029214  0.49823767 0.5070606  ... 0.507116   0.50782096 0.5144976 ]\n",
      " ...\n",
      " [0.49379626 0.49402764 0.4913916  ... 0.4954754  0.49808016 0.48922092]\n",
      " [0.5146677  0.5107169  0.5075194  ... 0.5018823  0.51208967 0.49710515]\n",
      " [0.4972319  0.5026027  0.49866775 ... 0.4938344  0.5048814  0.49989307]]\n"
     ]
    }
   ],
   "source": [
    "predictions, y_pred_avg = ensemble_models(\n",
    "    model_paths=model_paths, \n",
    "    cxr_filepath=cxr_filepath, \n",
    "    cxr_labels=cxr_labels, \n",
    "    cxr_pair_template=cxr_pair_template, \n",
    "    cache_dir=cache_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save averaged preds\n",
    "pred_name = \"chexpert_preds.npy\" # add name of preds\n",
    "# pred_name=\"chx.txt\"\n",
    "predictions_dir = predictions_dir / pred_name\n",
    "np.save(file=predictions_dir, arr=y_pred_avg)\n",
    "# np.savetxt(predictions_dir, y_pred_avg, fmt=\"%.6f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_dir = Path(\"../predictions\")\n",
    "# predictions_dir.mkdir(parents=True, exist_ok=True)  # Ensure directory exists\n",
    "\n",
    "# pred_file = predictions_dir / \"chexpert_preds.txt\"  # Save as a .txt file instead of .npy\n",
    "# np.savetxt(pred_file, y_pred_avg, fmt=\"%.6f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        filename                                         impression  \\\n",
      "0  s52100637.txt  1. Unchanged appearance of mild pulmonary edem...   \n",
      "1  s52100637.txt  1. Unchanged appearance of mild pulmonary edem...   \n",
      "2  s52100637.txt  1. Unchanged appearance of mild pulmonary edem...   \n",
      "3  s52974196.txt           Moderate pulmonary edema.checkpoint_9000   \n",
      "4  s52974196.txt                          Moderate pulmonary edema.   \n",
      "\n",
      "     study_id  subject_id                                             report  \\\n",
      "0  52100637.0  10249381.0  FINAL REPORT\\n EXAMINATION:  Chest pain\\n \\n I...   \n",
      "1  52100637.0  10249381.0  FINAL REPORT\\n EXAMINATION:  Chest pain\\n \\n I...   \n",
      "2  52100637.0  10249381.0  FINAL REPORT\\n EXAMINATION:  Chest pain\\n \\n I...   \n",
      "3  52974196.0  10245890.0  FINAL REPORT\\n INDICATION:  ___-year-old with ...   \n",
      "4  52974196.0  10245890.0  FINAL REPORT\\n INDICATION:  ___-year-old with ...   \n",
      "\n",
      "   Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
      "0          0.0           1.0            0.0    1.0   \n",
      "1          0.0           1.0            0.0    1.0   \n",
      "2          0.0           1.0            0.0    1.0   \n",
      "3          0.0           0.0            0.0    1.0   \n",
      "4          0.0           0.0            0.0    1.0   \n",
      "\n",
      "   Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n",
      "0                         0.0       0.0          0.0           0.0   \n",
      "1                         0.0       0.0          0.0           0.0   \n",
      "2                         0.0       0.0          0.0           0.0   \n",
      "3                         0.0       0.0          0.0           0.0   \n",
      "4                         0.0       0.0          0.0           0.0   \n",
      "\n",
      "   No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \\\n",
      "0         0.0               0.0            0.0        0.0           0.0   \n",
      "1         0.0               0.0            0.0        0.0           0.0   \n",
      "2         0.0               0.0            0.0        0.0           0.0   \n",
      "3         0.0               0.0            0.0        0.0           0.0   \n",
      "4         0.0               0.0            0.0        0.0           0.0   \n",
      "\n",
      "   Support Devices  \n",
      "0              0.0  \n",
      "1              0.0  \n",
      "2              0.0  \n",
      "3              0.0  \n",
      "4              0.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the mimic-impressions.csv file\n",
    "impressions_df = pd.read_csv(\"../test_data/mimic_impressions.csv\")\n",
    "\n",
    "# Extract numeric study_id from filename and convert to float\n",
    "impressions_df[\"study_id\"] = impressions_df[\"filename\"].str.extract(r\"s(\\d+)\")[0].astype(float)\n",
    "\n",
    "# Load the second file\n",
    "data_df = pd.read_csv(\"../MIMIC_CXR_report_phenotypes.csv\", encoding='utf-8', encoding_errors='replace')\n",
    "\n",
    "# Merge data_df with impressions_df to preserve duplicate occurrences of study_id\n",
    "filtered_df = impressions_df.merge(data_df, on=\"study_id\", how=\"inner\")\n",
    "filtered_df = filtered_df.fillna(0)\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(filtered_df.iloc[0:5])\n",
    "\n",
    "# Save the filtered data\n",
    "filtered_df.to_csv(\"filtered_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "cxr_true_labels_path: Optional[str] = 'filtered_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Evaluate Results\n",
    "If ground truth labels are available, compute AUC on each pathology to evaluate the performance of the zero-shot model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, hamming_loss\n",
    "\n",
    "def evaluate1(y_pred, y_true, cxr_labels):\n",
    "    \"\"\"\n",
    "    Evaluates a multi-label classification model.\n",
    "\n",
    "    Args:\n",
    "        y_pred (numpy.ndarray): Predicted probabilities (shape: [num_samples, num_classes]).\n",
    "        y_true (numpy.ndarray): True labels (binary) (shape: [num_samples, num_classes]).\n",
    "        cxr_labels (list): List of class labels.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing accuracy, precision, recall, F1-score, and Hamming Loss.\n",
    "    \"\"\"\n",
    "    num_classes = y_true.shape[1]\n",
    "    results = {}\n",
    "\n",
    "    # Convert predictions to binary (threshold 0.5)\n",
    "    y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "    num_all_zero_rows = np.sum(np.all(y_pred_binary == 0, axis=1))\n",
    "\n",
    "    print(\"Number of rows where all values are 0:\", num_all_zero_rows)\n",
    "    # Ensure y_true is binary (no unexpected values)\n",
    "    y_true = (y_true > 0).astype(int)\n",
    "\n",
    "    # Compute accuracy per class\n",
    "    class_accuracies = [accuracy_score(y_true[:, i], y_pred_binary[:, i]) for i in range(num_classes)]\n",
    "    overall_accuracy = accuracy_score(y_true.flatten(), y_pred_binary.flatten())  # Micro accuracy\n",
    "\n",
    "    # Compute Precision, Recall, and F1-score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred_binary, average=None)\n",
    "\n",
    "    # Compute Hamming Loss (Lower is better)\n",
    "    hamming = hamming_loss(y_true, y_pred_binary)\n",
    "\n",
    "    # Store results\n",
    "    results[\"Accuracy per class\"] = dict(zip(cxr_labels, class_accuracies))\n",
    "    results[\"Overall Accuracy\"] = overall_accuracy\n",
    "    results[\"Precision\"] = dict(zip(cxr_labels, precision))\n",
    "    results[\"Recall\"] = dict(zip(cxr_labels, recall))\n",
    "    results[\"F1-score\"] = dict(zip(cxr_labels, f1))\n",
    "    results[\"Hamming Loss\"] = hamming\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test_true: (328, 14)\n",
      "Shape of test_pred: (328, 14)\n",
      "Sample Prediction: [0.49611872 0.49636057 0.5076487  0.49583548 0.4958477  0.5075441\n",
      " 0.4888963  0.48862243 0.4973661  0.502445   0.49782807 0.51039606\n",
      " 0.4975381  0.51275533]\n",
      "Sample True Labels: [0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Number of rows where all values are 0: 6\n",
      "Evaluation Results: {'Accuracy per class': {'Atelectasis': 0.5152439024390244, 'Cardiomegaly': 0.5548780487804879, 'Consolidation': 0.4847560975609756, 'Edema': 0.6859756097560976, 'Enlarged Cardiomediastinum': 0.5670731707317073, 'Fracture': 0.6310975609756098, 'Lung Lesion': 0.573170731707317, 'Lung Opacity': 0.5914634146341463, 'No Finding': 0.2530487804878049, 'Pleural Effusion': 0.5274390243902439, 'Pleural Other': 0.5060975609756098, 'Pneumonia': 0.375, 'Pneumothorax': 0.4573170731707317, 'Support Devices': 0.46646341463414637}, 'Overall Accuracy': 0.5135017421602788, 'Precision': {'Atelectasis': 0.23076923076923078, 'Cardiomegaly': 0.23134328358208955, 'Consolidation': 0.041916167664670656, 'Edema': 0.12871287128712872, 'Enlarged Cardiomediastinum': 0.05405405405405406, 'Fracture': 0.01652892561983471, 'Lung Lesion': 0.0, 'Lung Opacity': 0.3313253012048193, 'No Finding': 0.12637362637362637, 'Pleural Effusion': 0.38427947598253276, 'Pleural Other': 0.0125, 'Pneumonia': 0.03940886699507389, 'Pneumothorax': 0.028735632183908046, 'Support Devices': 0.33760683760683763}, 'Recall': {'Atelectasis': 0.6885245901639344, 'Cardiomegaly': 0.4189189189189189, 'Consolidation': 0.4375, 'Edema': 0.4642857142857143, 'Enlarged Cardiomediastinum': 0.8, 'Fracture': 0.5, 'Lung Lesion': 0.0, 'Lung Opacity': 0.7051282051282052, 'No Finding': 0.21100917431192662, 'Pleural Effusion': 0.8627450980392157, 'Pleural Other': 0.3333333333333333, 'Pneumonia': 0.4444444444444444, 'Pneumothorax': 0.35714285714285715, 'Support Devices': 0.797979797979798}, 'F1-score': {'Atelectasis': 0.345679012345679, 'Cardiomegaly': 0.2980769230769231, 'Consolidation': 0.07650273224043716, 'Edema': 0.20155038759689922, 'Enlarged Cardiomediastinum': 0.10126582278481013, 'Fracture': 0.032, 'Lung Lesion': 0.0, 'Lung Opacity': 0.45081967213114754, 'No Finding': 0.15807560137457044, 'Pleural Effusion': 0.5317220543806647, 'Pleural Other': 0.024096385542168676, 'Pneumonia': 0.07239819004524888, 'Pneumothorax': 0.05319148936170213, 'Support Devices': 0.4744744744744745}, 'Hamming Loss': 0.4864982578397213}\n"
     ]
    }
   ],
   "source": [
    "# Generate ground truth labels\n",
    "test_true = make_true_labels(cxr_true_labels_path=cxr_true_labels_path, cxr_labels=cxr_labels)\n",
    "\n",
    "# Ensure predictions are in the correct format\n",
    "test_pred = y_pred_avg\n",
    "\n",
    "# Print shapes and sample values for debugging\n",
    "print(\"Shape of test_true:\", test_true.shape)\n",
    "print(\"Shape of test_pred:\", test_pred.shape)\n",
    "print(\"Sample Prediction:\", test_pred[0])\n",
    "print(\"Sample True Labels:\", test_true[0])\n",
    "\n",
    "# Ensure test_true and test_pred are NumPy arrays\n",
    "test_true = np.array(test_true)\n",
    "test_pred = np.array(test_pred)\n",
    "\n",
    "# Evaluate model\n",
    "cxr_results = evaluate1(test_pred, test_true, cxr_labels)\n",
    "\n",
    "# Bootstrap evaluations for 95% confidence intervals\n",
    "# bootstrap_results = bootstrap(test_pred, test_true, cxr_labels)\n",
    "\n",
    "# Print evaluation results\n",
    "print(\"Evaluation Results:\", cxr_results)\n",
    "# print(\"Bootstrap Results:\", bootstrap_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bootstrap_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[276], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# display AUC with confidence intervals\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mbootstrap_results\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bootstrap_results' is not defined"
     ]
    }
   ],
   "source": [
    "# display AUC with confidence intervals\n",
    "bootstrap_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
